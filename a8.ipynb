{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lSqUtyytAWWG"
      },
      "source": [
        "# Convolutional Neural Networks\n",
        "\n",
        "![LeNet5](https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png)\n",
        "\n",
        "Convolutional Neural Networks are particularly well suited for image classification. In https://www.tensorflow.org/tutorials/images/cnn and https://keras.io/examples/vision/mnist_convnet some well performing examples are given. First, modify the network to include a\n",
        "single convolutional layer, a single pooling layer, and a single fully connected layer only.  \n",
        "Then, incrementally add more complexity and regularization, particularly:\n",
        "- consider the network architecture of LeNet5 (shown in the figure) and get inspired by AlexNet.\n",
        "  (As AlexNet was designed for much larger input images (227x227) it cannot be applied 1:1 to MNIST images (28x28)).\n",
        "- try to further improve the test error\n",
        "  (Remember to only use your validation set to tweak your hyper parameters!)\n",
        "\n",
        "Record training and test accuracies with TensorBoard.  \n",
        "How many parameters have your networks, also compared to a standard 128-64-64-10 MLP network from last sheet?  \n",
        "How long does it take to train them?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6O1OyjmIAsjV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import tensorboard as tb\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cifar10 dataset\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# MNNIST dataset\n",
        "\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(36):\n",
        "    plt.subplot(6,6,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "    # The CIFAR labels happen to be arrays, \n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lets start with the single convolutional layer, a single pooling layer, and a single fully connected layer only.\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "log_dir = \"./logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5, validation_split=0.1)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPooli  (None, 15, 15, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPooli  (None, 6, 6, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66570 (260.04 KB)\n",
            "Trainable params: 66570 (260.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.5257 - accuracy: 0.4479\n",
            "Epoch 2/2\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1646 - accuracy: 0.5907\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1123 - accuracy: 0.6131\n",
            "0.613099992275238\n"
          ]
        }
      ],
      "source": [
        "# LeNet5 model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "# Tensorboard training and test accuracy\n",
        "\n",
        "log_dir = \"./logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
        "\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1563/1563 [==============================] - 33s 21ms/step - loss: 1.2637 - accuracy: 0.5511\n",
            "Epoch 2/2\n",
            "1563/1563 [==============================] - 34s 22ms/step - loss: 0.8378 - accuracy: 0.7070\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.9454 - accuracy: 0.6796\n",
            "0.6796000003814697\n"
          ]
        }
      ],
      "source": [
        "# Further improvements --> add more layers and batch normalization\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
        "\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# call tensorboard\n",
        "%tensorboard --logdir ./logs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By increasing the number of layers and adding normalization we increased the overall accuracy by 5% (from 63 to 68) but the runtime increased by almost 3x. \n",
        "\n",
        "The first simple model has 72906 parameters and the second has 66570 parameters which is a little more compared to the models of the last sheet."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Tynpiod0flPF",
        "sUmzV32tMjAH",
        "zpkVt2EGMr8c",
        "FlWcaSZ5NqpZ",
        "ft3PktQ9ecFi",
        "4HiRxowSi77E"
      ],
      "name": "CNNs",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
